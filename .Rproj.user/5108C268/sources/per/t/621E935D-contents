---
title: "First look at data and random forests"
author: "Szymon Makulec"
date: "2024-11-18"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, include=FALSE}
data <- readRDS("data_after_preparation.rds")

```
Basic statistics
```{r, warning=FALSE}
library(tidyverse)
library(DT)
summary_data <- summary(data)
summary_df <- as.data.frame(t(summary_data))
datatable(summary_df, 
          options = list(pageLength = 6, autoWidth = TRUE), rownames = FALSE )
```

Dane nie zawierają żadnych anomalii ani nierealistycznych wartości, co zapewnia integralność zbioru danych. W naszych danych tylko  294/8717 osób jest klasyfikowanych jako wysokie ryzyko, więc musimy szczególnie skupić się na tej małej grupie.

```{r}
library(corrplot)
correlation_matrix <- cor(data[, sapply(data, is.numeric)])
corrplot(correlation_matrix, method = "circle", tl.pos = "n" )
```

Na początku wydaje się, że ryzyko kredytowe nie jest znacząco skorelowane z żadnym z naszych predyktorów, ale przetestujemy to. Widzimy silne dodatnie i ujemne korelacje między niektórymi predyktorami, ale na razie nas to nie niepokoi, ponieważ możemy użyć lasu losowego, który jest odporny na autokorelację predyktorów.

Dzielimy dane na numeryczne i kategoryczne
```{r}
data_num <- data %>% select_if(is.numeric)
data_fac <- data %>% select_if(is.factor)

```

Wizualizacje dla wartości numerycznych
```{r}
library(caret)

featurePlot(x = data_num[,c(1:4)],
            y = data$credit_risk,
            plot = "box",
            scales = list( y = list(relation="free"),
                           x = list(rot=90) ),
            layout = c(2,2))
```
Widać, że największy wpływ na credit_risk mają age i years_in_job


Tabele wpływów zmiennych typu factor ( niektóre błędnie trafiły do numerycznych) na credit risk.
Należy powiedzieć, że 0 i 1 po lewej stronie każdej tabeli informują nas o ryzyku kredytowym, a 0 i 1 na górze oznaczają obecność danej zmiennej.
```{r}
for ( i in 1 : ncol(data_fac) ){
  print(names(data_fac[i]))
  print(prop.table(table(data$credit_risk, data_fac[[i]])))
}

for ( i in 5 : ncol(data_num) ){
  print(names(data_num[i]))
  print(prop.table(table(data$credit_risk, data_num[[i]])))
}
```

(Moim zdaniem) Najważniejsze zmienne objaśniające : credit_history, overdue_payments, owns_property, other_loans, active_loans_0, active_loans_1, active_loans_2, children_1, children_2, children_3, education_podstawowe, education_wyższe, city_duże, city_małe, marital_status_rozwiedziony_rozwiedziona


Ustalenie podziału danych
```{r}
set.seed(223)
podzial <- createDataPartition(
  y=data$credit_risk,
  times = 1,
  p=0.8,
  list=F
)

```


```{r}
trening <- df_balanced[podzial,]
test <- data[-podzial,]

trening[trening$credit_risk==1,]
test[test$credit_risk==1,]
```

Zarówno w zbiorze testowym jak i treningowym mamy sytuacje typu 0 oraz 1. Szczególnie w zbiorze treningowym interesuje nas żeby model nie przeuczył się w stronę 0 więc sztucznie tworzymy nowe obserwacje.
```{r}
minority <- trening[trening$credit_risk == "1", ]
majority <- trening[trening$credit_risk == "0", ]

minority_oversampled <- minority[sample(1:nrow(minority), 
                                        size = nrow(majority), 
                                        replace = TRUE), ]
trening_balanced <- rbind(majority, minority_oversampled)
trening_balanced

```

Trenujemy lasu losowe
```{r}
library(randomForest)
las <- randomForest(credit_risk~., trening)
las$type
las$importance
las$ntree
las
```
Predykcje dla zbioru testowego
```{r}
pr <- predict(las, test)
confusionMatrix(pr, test$credit_risk)
```
Jak na pierwszy las losowy to tragedii nie ma, ale mogłoby być lepiej.

Próbujemy stworzyć las inną metodą
```{r}
model <- train(credit_risk ~ .,
               data = trening,
               method = 'rf')
```

```{r}
model
prognoza <-  predict(model, test)
confusionMatrix(prognoza, test$credit_risk)
```
Modele wyszły jednakowo

```{r}
las2 <- randomForest(credit_risk~., trening, ntree = 1000)
```

```{r}
pr2 <- predict(las2, test)
confusionMatrix(pr2, test$credit_risk)
```
```{r}
las3 <- randomForest(credit_risk~., trening, ntree = 10000)
```
```{r}
pr3 <- predict(las3, test)
confusionMatrix(pr3, test$credit_risk)
```
Włączanie większej ilości drzew nie przyniosło lepszych efektów.

```{r}
lass <- randomForest(credit_risk~., trening, ntree = 60)
lass
```
Predykcje dla zbioru testowego
```{r}
prs <- predict(lass, test)
confusionMatrix(prs, test$credit_risk)
```
Las z 60 drzewami na zbiorze testowym radzi sobie tak samo jak ten z 10000.

```{r}
saveRDS(lass, "model_rf.rds")
```








