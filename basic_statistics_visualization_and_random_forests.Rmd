---
title: "First look at data and random forests"
author: "Szymon Makulec"
date: "2024-11-18"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
set.seed(223)
```

```{r, include=FALSE}
data <- readRDS("data_after_preparation.rds")

```
Basic statistics
```{r, warning=FALSE}
library(tidyverse)
library(DT)

summary_data <- summary(data)
summary_df <- as.data.frame(t(summary_data))
datatable(summary_df, 
          options = list(pageLength = 6, autoWidth = TRUE), rownames = FALSE )
```

Dane nie zawierają żadnych anomalii ani nierealistycznych wartości, co zapewnia integralność zbioru danych. W naszych danych tylko  294/8717 osób jest klasyfikowanych jako wysokie ryzyko, więc musimy szczególnie skupić się na tej małej grupie.

```{r}
library(corrplot)
correlation_matrix <- cor(data[, sapply(data, is.numeric)])
corrplot(correlation_matrix, method = "circle", tl.pos = "n" )
```

Na początku wydaje się, że ryzyko kredytowe nie jest znacząco skorelowane z żadnym z naszych predyktorów, ale przetestujemy to. Widzimy silne dodatnie i ujemne korelacje między niektórymi predyktorami, ale na razie nas to nie niepokoi, ponieważ możemy użyć lasu losowego, który jest odporny na autokorelację predyktorów.

Dzielimy dane na numeryczne i kategoryczne
```{r}
data_num <- data %>% select_if(is.numeric)
data_fac <- data %>% select_if(is.factor)

```

Wizualizacje dla wartości numerycznych
```{r}
library(caret)

featurePlot(x = data_num[,c(1:4)],
            y = data$credit_risk,
            plot = "box",
            scales = list( y = list(relation="free"),
                           x = list(rot=90) ),
            layout = c(2,2))
```
Widać, że największy wpływ na credit_risk mają age i years_in_job


Tabele wpływów zmiennych typu factor ( niektóre błędnie trafiły do numerycznych) na credit risk.
Należy powiedzieć, że 0 i 1 po lewej stronie każdej tabeli informują nas o ryzyku kredytowym, a 0 i 1 na górze oznaczają obecność danej zmiennej.
```{r}
for ( i in 1 : ncol(data_fac) ){
  print(names(data_fac[i]))
  print(prop.table(table(data$credit_risk, data_fac[[i]])))
}

for ( i in 5 : ncol(data_num) ){
  print(names(data_num[i]))
  print(prop.table(table(data$credit_risk, data_num[[i]])))
}
```

(Moim zdaniem) Najważniejsze zmienne objaśniające : credit_history, overdue_payments, owns_property, other_loans, active_loans_0, active_loans_1, active_loans_2, children_1, children_2, children_3, education_podstawowe, education_wyższe, city_duże, city_małe, marital_status_rozwiedziony_rozwiedziona


Ustalenie podziału danych

```{r}
minority <- data[data$credit_risk == "1", ]
majority <- data[data$credit_risk == "0", ]

minority_oversampled <- minority[sample(1:nrow(minority), 
                                        size = nrow(majority), 
                                        replace = TRUE), ]
df_balanced <- rbind(majority, minority_oversampled)

```

```{r}
podzial <- createDataPartition(
  y=df_balanced$credit_risk,
  times = 1,
  p=0.8,
  list=F
)

```

```{r}
trening <- df_balanced[podzial,]
test <- df_balanced[-podzial,]

head(trening[trening$credit_risk==1,])
head(test[test$credit_risk==1,])
```

Zarówno w zbiorze testowym jak i treningowym mamy sytuacje typu 0 oraz 1. Szczególnie w zbiorze treningowym interesuje nas żeby model nie przeuczył się w stronę 0 więc sztucznie tworzymy nowe obserwacje.


Trenujemy lasu losowe
```{r}

library(randomForest)
las <- randomForest(credit_risk~., trening)
las$type
las$importance
las$ntree
las
```
```{r}
saveRDS(las, "model_las.rds")
```

```{r}
las <- readRDS("model_las.rds")
```

Predykcje dla zbioru testowego
```{r}

pr <- predict(las, test)
confusionMatrix(pr, test$credit_risk)
```
Jak na pierwszy las losowy to tragedii nie ma, ale mogłoby być lepiej.

Próbujemy stworzyć las inną metodą

```{r}
lass <- randomForest(credit_risk~., trening, ntree = 100)
lass
```
```{r}
saveRDS(lass, "model_lass.rds")
```

```{r}
lass <- readRDS("model_lass.rds")
```

```{r}

prr <- predict(lass, test)
confusionMatrix(prr, test$credit_risk)
```











